{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40moaFPgeIfB"
      },
      "source": [
        "# Apple Stock Predictor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmlwzkTBeIfD"
      },
      "source": [
        "## By Derrick Lin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ7wEluveIfD"
      },
      "source": [
        "# Abstract\n",
        "<!--This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize:\n",
        "- what your goal/problem is\n",
        "- what the data used represents\n",
        "- the solution/what you did\n",
        "- major results you came up with (mention how results are measured)\n",
        "\n",
        "__NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables-->\n",
        "\n",
        "Our goal is to evaluate the effectiveness of unsupervised machine learning in categorizing stocks based on risk-return profiles to optimize investment portfolios. We use historical stock market data, including daily prices, volatility, and financial ratios, to represent stock characteristics. Through clustering techniques and dimensionality reduction, we hope to identify distinct categories that reflect different risk-return dynamics. Additionally, performance will be measured by evaluating portfolio stability compared to traditional methods, which will show us how useful unsupervised learning is for predicting stocks in real-world scenarios.\n",
        "\n",
        "In this study, we offer specific insights into applying unsupervised learning for stock prediction, focusing on Apple Inc's data from 1980 to 2022. Our analysis compares the predictive accuracy of an ARIMA model against a naive benchmark, which shows nearly identical mean squared error (MSE) and root mean squared error (RMSE). This research highlights the need to use complex algorithms in stock price prediction and provides a framework for using unsupervised learning techniques in portfolio optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h-APqNaeIfD"
      },
      "source": [
        "# Background\n",
        "\n",
        "<!--Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
        "\n",
        "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts.\n",
        "\n",
        "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. -->\n",
        "\n",
        "A stock market is a market where people are able to purchase shares from public companies. These shares can help an individual gain profits, the company to raise capital, and provide people a way to invest in companies they believe have potential<a name=\"simplilearn\"></a>[<sup>[1]</sup>](#simplilearn). It is for these reasons that finding a way to predict how stock market prices may change is crucial.\n",
        "\n",
        "The stock market is known to be extremely unpredictable and full of unknown variables, which can influence stock prices one way or another.  For many years, researchers have been working to try to predict stock prices. However, this has been quite difficult with the presence of unexpected variables like the pandemic<a name=\"projectpro\"></a>[<sup>[2]</sup>](#projectpro). Therefore, analysts have instead tried to focus on short term predictions that estimate how the stock market could’ve changed. Since the stock market is so complex considering the many variables influencing its change, AI steps in to help us process these variables.\n",
        "\n",
        "There are already several different types of models used to predict the stock market, and two different ways to analyze the stocks. Fundamental analysis looks at a company stock’s intrinsic value and analyzes historical as well as current data. They are used mainly with long-term investments. Technical analysis looks at measurable data of the stock activities as well as analyzing present and historical data for short-term investments<a name=\"neptuneai\"></a>[<sup>[3]</sup>](#neptuneai). In addition, technical analysis is influenced by current news while fundamental analysis is not really affected by them. In the case of Neptune a.i, they have chosen to use technical analysis with a Long Short Term Memory framework to build a model to predict the stock market.\n",
        "\n",
        "South Dakota State University has also developed their own A.I model, dubbed “ALERTA-NET” where they have incorporated macroeconomic data in their model which have resulted in more accurate predictions<a name=\"sdsu\"></a>[<sup>[4]</sup>](#sdsu). It is examples like these that stand to prove that researchers are still looking to build models that can predict the stock market with higher accuracy. The uncertainty of the stock market makes this task so difficult, and the importance of the stock market in terms of the economy as well as profits makes the pursuit of accurate stock market prediction models so crucial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBjktXobeIfD"
      },
      "source": [
        "# Problem Statement\n",
        "\n",
        "<!--Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once). -->\n",
        "\n",
        "Our objective is to build a machine learning model that predicts Apple's future stock prices for the years 1980 to 2021, using past data from Yahoo Finance. We will use Time Series Analysis and Exploratory Data Analysis (EDA) techniques to identify patterns, trends, and potential factors that influence Apple's historical stock performance. To measure our model's accuracy, we will use Mean Squared Error (MSE) and Root Mean Squared Error (RMSE), which quantify the accuracy of our predictions of actual stock prices. Additionally, our problem is highly replicable in financial markets, where investors and analysts often look for such forecasts to make their decisions. For an ML-relevant solution, we will use time series forecasting models like ARIMA, SARIMA, or LSTM networks. These models will analyze historical stock prices and relevant financial indicators to predict future stock movements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vVX_Nj8eIfE"
      },
      "source": [
        "# Data\n",
        "\n",
        "<!--Detail how/where you obtained the data and cleaned it (if necessary)\n",
        "\n",
        "If the data cleaning process is very long (e.g., elaborate text processing) consider describing it briefly here in text, and moving the actual clearning process to another notebook in your repo (include a link here!).  The idea behind this approach: this is a report, and if you blow up the flow of the report to include a lot of code it makes it hard to read.\n",
        "\n",
        "Please give the following infomration for each dataset you are using\n",
        "- link/reference to obtain it\n",
        "- description of the size of the dataset (# of variables, # of observations)\n",
        "- what an observation consists of\n",
        "- what some critical variables are, how they are represented\n",
        "- any special handling, transformations, cleaning, etc you have done should be demonstrated here!-->\n",
        "\n",
        "\n",
        "***Data Description: Apple Inc. Stock Prices (1980-2021)***\n",
        "\n",
        "- We will be using the historical stock prices of Apple, from December 11, 1980, to June 16, 2022. The dataset from Yahoo Finance consists of various metrics, including opening prices, closing prices, high prices, low prices, adjusted closing prices, and trading volumes for each trading day.\n",
        "\n",
        "***Dataset Information:***\n",
        "\n",
        "- Dataset Source: Apple Stock Price (1980-2021) Kaggle Dataset\n",
        "\n",
        "***Dataset Overview:***\n",
        "\n",
        "- Observations: The dataset has a total of 7 variables and 10,500 observations, where each observation represents daily stock metrics for Apple Inc.\n",
        "\n",
        "***Enhancing the analysis:***\n",
        "\n",
        "- Data Cleaning and Transformation: We may conduct data cleaning, handling missing values, and outliers, and ensuring the temporal integrity of the dataset for time-series analysis.\n",
        "- Normalize Prices: Standardize price data to easily compare volatility and returns across different stocks. This involves expressing price changes as percentages.\n",
        "- Adjust Stock Names: Use official names instead of tickers for better readability in reports.\n",
        "- Explore daily trading patterns in the dataset: Maybe look for more datasets with multiple observations per day for a more detailed analysis of short-term stock volatility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OolBL8B5eIfE",
        "outputId": "150959ac-dc7f-4986-d064-4f59b1254979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         Date      Open      High       Low     Close  Adj Close     Volume\n",
            "0  1980-12-12  0.128348  0.128906  0.128348  0.128348   0.100178  469033600\n",
            "1  1980-12-15  0.122210  0.122210  0.121652  0.121652   0.094952  175884800\n",
            "2  1980-12-16  0.113281  0.113281  0.112723  0.112723   0.087983  105728000\n",
            "3  1980-12-17  0.115513  0.116071  0.115513  0.115513   0.090160   86441600\n",
            "4  1980-12-18  0.118862  0.119420  0.118862  0.118862   0.092774   73449600\n"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('AAPL.csv') # load the dataset\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W98nvp74eIfE",
        "outputId": "666af7d4-70c0-463d-f008-dcdf49be95e7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Year</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>1980-12-12</td>\n",
              "      <td>0.128348</td>\n",
              "      <td>0.128906</td>\n",
              "      <td>0.128348</td>\n",
              "      <td>0.128348</td>\n",
              "      <td>0.100178</td>\n",
              "      <td>469033600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>1980-12-15</td>\n",
              "      <td>0.122210</td>\n",
              "      <td>0.122210</td>\n",
              "      <td>0.121652</td>\n",
              "      <td>0.121652</td>\n",
              "      <td>0.094952</td>\n",
              "      <td>175884800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>1980-12-16</td>\n",
              "      <td>0.113281</td>\n",
              "      <td>0.113281</td>\n",
              "      <td>0.112723</td>\n",
              "      <td>0.112723</td>\n",
              "      <td>0.087983</td>\n",
              "      <td>105728000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>1980-12-17</td>\n",
              "      <td>0.115513</td>\n",
              "      <td>0.116071</td>\n",
              "      <td>0.115513</td>\n",
              "      <td>0.115513</td>\n",
              "      <td>0.090160</td>\n",
              "      <td>86441600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>1980-12-18</td>\n",
              "      <td>0.118862</td>\n",
              "      <td>0.119420</td>\n",
              "      <td>0.118862</td>\n",
              "      <td>0.118862</td>\n",
              "      <td>0.092774</td>\n",
              "      <td>73449600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>2022-06-13</td>\n",
              "      <td>132.869995</td>\n",
              "      <td>135.199997</td>\n",
              "      <td>131.440002</td>\n",
              "      <td>131.880005</td>\n",
              "      <td>131.880005</td>\n",
              "      <td>122207100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>2022-06-14</td>\n",
              "      <td>133.130005</td>\n",
              "      <td>133.889999</td>\n",
              "      <td>131.479996</td>\n",
              "      <td>132.759995</td>\n",
              "      <td>132.759995</td>\n",
              "      <td>84784300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>2022-06-15</td>\n",
              "      <td>134.289993</td>\n",
              "      <td>137.339996</td>\n",
              "      <td>132.160004</td>\n",
              "      <td>135.429993</td>\n",
              "      <td>135.429993</td>\n",
              "      <td>91533000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>2022-06-16</td>\n",
              "      <td>132.080002</td>\n",
              "      <td>132.389999</td>\n",
              "      <td>129.039993</td>\n",
              "      <td>130.059998</td>\n",
              "      <td>130.059998</td>\n",
              "      <td>108123900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>2022-06-17</td>\n",
              "      <td>130.070007</td>\n",
              "      <td>133.080002</td>\n",
              "      <td>129.809998</td>\n",
              "      <td>131.559998</td>\n",
              "      <td>131.559998</td>\n",
              "      <td>134118500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10468 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date        Open        High         Low       Close   Adj Close  \\\n",
              "Year                                                                          \n",
              "1980 1980-12-12    0.128348    0.128906    0.128348    0.128348    0.100178   \n",
              "1980 1980-12-15    0.122210    0.122210    0.121652    0.121652    0.094952   \n",
              "1980 1980-12-16    0.113281    0.113281    0.112723    0.112723    0.087983   \n",
              "1980 1980-12-17    0.115513    0.116071    0.115513    0.115513    0.090160   \n",
              "1980 1980-12-18    0.118862    0.119420    0.118862    0.118862    0.092774   \n",
              "...         ...         ...         ...         ...         ...         ...   \n",
              "2022 2022-06-13  132.869995  135.199997  131.440002  131.880005  131.880005   \n",
              "2022 2022-06-14  133.130005  133.889999  131.479996  132.759995  132.759995   \n",
              "2022 2022-06-15  134.289993  137.339996  132.160004  135.429993  135.429993   \n",
              "2022 2022-06-16  132.080002  132.389999  129.039993  130.059998  130.059998   \n",
              "2022 2022-06-17  130.070007  133.080002  129.809998  131.559998  131.559998   \n",
              "\n",
              "         Volume  \n",
              "Year             \n",
              "1980  469033600  \n",
              "1980  175884800  \n",
              "1980  105728000  \n",
              "1980   86441600  \n",
              "1980   73449600  \n",
              "...         ...  \n",
              "2022  122207100  \n",
              "2022   84784300  \n",
              "2022   91533000  \n",
              "2022  108123900  \n",
              "2022  134118500  \n",
              "\n",
              "[10468 rows x 7 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Extract year from the 'Date' column\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df = df.set_index('Year')\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ncAZ-vBHeIfF"
      },
      "outputs": [],
      "source": [
        "df['Daily_Return'] = (df['Close'] - df['Open']) / df['Open']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hCcxvWxGeIfF",
        "outputId": "0f64a6c0-e79d-4182-8ce2-b2ae61a468ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily_Return</th>\n",
              "      <th>Overnight_Return</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Year</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>1980-12-12</td>\n",
              "      <td>0.128348</td>\n",
              "      <td>0.128906</td>\n",
              "      <td>0.128348</td>\n",
              "      <td>0.128348</td>\n",
              "      <td>0.100178</td>\n",
              "      <td>469033600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.219481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>1980-12-15</td>\n",
              "      <td>0.122210</td>\n",
              "      <td>0.122210</td>\n",
              "      <td>0.121652</td>\n",
              "      <td>0.121652</td>\n",
              "      <td>0.094952</td>\n",
              "      <td>175884800</td>\n",
              "      <td>-0.004566</td>\n",
              "      <td>-0.219479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>1980-12-16</td>\n",
              "      <td>0.113281</td>\n",
              "      <td>0.113281</td>\n",
              "      <td>0.112723</td>\n",
              "      <td>0.112723</td>\n",
              "      <td>0.087983</td>\n",
              "      <td>105728000</td>\n",
              "      <td>-0.004926</td>\n",
              "      <td>-0.219476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>1980-12-17</td>\n",
              "      <td>0.115513</td>\n",
              "      <td>0.116071</td>\n",
              "      <td>0.115513</td>\n",
              "      <td>0.115513</td>\n",
              "      <td>0.090160</td>\n",
              "      <td>86441600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.219482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>1980-12-18</td>\n",
              "      <td>0.118862</td>\n",
              "      <td>0.119420</td>\n",
              "      <td>0.118862</td>\n",
              "      <td>0.118862</td>\n",
              "      <td>0.092774</td>\n",
              "      <td>73449600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.219481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>2022-06-13</td>\n",
              "      <td>132.869995</td>\n",
              "      <td>135.199997</td>\n",
              "      <td>131.440002</td>\n",
              "      <td>131.880005</td>\n",
              "      <td>131.880005</td>\n",
              "      <td>122207100</td>\n",
              "      <td>-0.007451</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>2022-06-14</td>\n",
              "      <td>133.130005</td>\n",
              "      <td>133.889999</td>\n",
              "      <td>131.479996</td>\n",
              "      <td>132.759995</td>\n",
              "      <td>132.759995</td>\n",
              "      <td>84784300</td>\n",
              "      <td>-0.002779</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>2022-06-15</td>\n",
              "      <td>134.289993</td>\n",
              "      <td>137.339996</td>\n",
              "      <td>132.160004</td>\n",
              "      <td>135.429993</td>\n",
              "      <td>135.429993</td>\n",
              "      <td>91533000</td>\n",
              "      <td>0.008489</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>2022-06-16</td>\n",
              "      <td>132.080002</td>\n",
              "      <td>132.389999</td>\n",
              "      <td>129.039993</td>\n",
              "      <td>130.059998</td>\n",
              "      <td>130.059998</td>\n",
              "      <td>108123900</td>\n",
              "      <td>-0.015294</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>2022-06-17</td>\n",
              "      <td>130.070007</td>\n",
              "      <td>133.080002</td>\n",
              "      <td>129.809998</td>\n",
              "      <td>131.559998</td>\n",
              "      <td>131.559998</td>\n",
              "      <td>134118500</td>\n",
              "      <td>0.011455</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10468 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date        Open        High         Low       Close   Adj Close  \\\n",
              "Year                                                                          \n",
              "1980 1980-12-12    0.128348    0.128906    0.128348    0.128348    0.100178   \n",
              "1980 1980-12-15    0.122210    0.122210    0.121652    0.121652    0.094952   \n",
              "1980 1980-12-16    0.113281    0.113281    0.112723    0.112723    0.087983   \n",
              "1980 1980-12-17    0.115513    0.116071    0.115513    0.115513    0.090160   \n",
              "1980 1980-12-18    0.118862    0.119420    0.118862    0.118862    0.092774   \n",
              "...         ...         ...         ...         ...         ...         ...   \n",
              "2022 2022-06-13  132.869995  135.199997  131.440002  131.880005  131.880005   \n",
              "2022 2022-06-14  133.130005  133.889999  131.479996  132.759995  132.759995   \n",
              "2022 2022-06-15  134.289993  137.339996  132.160004  135.429993  135.429993   \n",
              "2022 2022-06-16  132.080002  132.389999  129.039993  130.059998  130.059998   \n",
              "2022 2022-06-17  130.070007  133.080002  129.809998  131.559998  131.559998   \n",
              "\n",
              "         Volume  Daily_Return  Overnight_Return  \n",
              "Year                                             \n",
              "1980  469033600      0.000000         -0.219481  \n",
              "1980  175884800     -0.004566         -0.219479  \n",
              "1980  105728000     -0.004926         -0.219476  \n",
              "1980   86441600      0.000000         -0.219482  \n",
              "1980   73449600      0.000000         -0.219481  \n",
              "...         ...           ...               ...  \n",
              "2022  122207100     -0.007451          0.000000  \n",
              "2022   84784300     -0.002779          0.000000  \n",
              "2022   91533000      0.008489          0.000000  \n",
              "2022  108123900     -0.015294          0.000000  \n",
              "2022  134118500      0.011455          0.000000  \n",
              "\n",
              "[10468 rows x 9 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Overnight_Return'] = (df['Adj Close'] - df['Close']) / df['Close']\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QzAeIjtaeIfF",
        "outputId": "1955707e-6b8f-4c68-ae5a-9aff5fda9f41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Date                0\n",
            "Open                0\n",
            "High                0\n",
            "Low                 0\n",
            "Close               0\n",
            "Adj Close           0\n",
            "Volume              0\n",
            "Daily_Return        0\n",
            "Overnight_Return    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Normalize the stock prices (if needed)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Normalized_Price'] = scaler.fit_transform(df[['Close']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgTnBj3TeIfF"
      },
      "source": [
        "# Proposed Solution\n",
        "\n",
        "<!--In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
        "\n",
        "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
        "\n",
        "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. -->\n",
        "\n",
        "**Solution Overview:**\n",
        "\n",
        "Our solution aims to predict stock price movements using primarily unsupervised machine learning techniques. The focus will be on exploring the underlying patterns and structures in the stock market data without relying on labeled outcomes. The insights gained from unsupervised learning will then be used to inform a simple supervised model for price prediction.\n",
        "\n",
        "**Unsupervised Learning for Feature Extraction and Analysis**\n",
        "\n",
        "1. **Clustering for Market Segmentation**: We will use clustering algorithms, such as K-means and DBSCAN, to segment stocks based on historical price movements, trading volume, and other financial indicators. This will help us identify groups of stocks with similar behavior.\n",
        "\n",
        "2. **Dimensionality Reduction**: Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (t-SNE) will be applied to reduce the dimensionality of the data while preserving its structure. This will assist in visualizing the stock market data and identifying key features.\n",
        "\n",
        "3. **Association Rule Mining**: We will explore association rule mining to uncover relationships between different stocks or financial indicators. This can reveal interesting patterns, such as stocks that tend to move together.\n",
        "\n",
        "4. **Anomaly Detection**: Techniques like Isolation Forest and One-Class SVM will be used to detect anomalies in the stock market data, which could indicate potential market disruptions or opportunities.\n",
        "\n",
        "**Supervised Learning for Price Prediction**\n",
        "\n",
        "After extracting insights and features using unsupervised techniques, we will employ a simple supervised learning model to predict stock price movements:\n",
        "\n",
        "1. **Logistic Regression**: Based on the features and patterns identified through unsupervised learning, we will use logistic regression to predict whether a stock's price will go up or down in the next trading period.\n",
        "\n",
        "**Model Evaluation**\n",
        "\n",
        "We will evaluate the performance of our unsupervised models using metrics such as silhouette score (for clustering quality) and reconstruction error (for dimensionality reduction). The supervised logistic regression model will be evaluated using accuracy, precision, recall, and F1 score.\n",
        "\n",
        "**Implementation Details**\n",
        "\n",
        "We plan to implement our solution using Python, with libraries such as `scikit-learn` for machine learning algorithms, `pandas` for data manipulation, and `matplotlib` and `seaborn` for data visualization. The implementation will include:\n",
        "\n",
        "1. **Data Preprocessing**: Loading the dataset, handling missing values, and normalizing the features.\n",
        "2. **Unsupervised Learning**: Applying clustering, dimensionality reduction, association rule mining, and anomaly detection techniques.\n",
        "3. **Feature Selection**: Selecting relevant features based on insights from unsupervised learning.\n",
        "4. **Supervised Learning**: Training and evaluating the logistic regression model.\n",
        "5. **Model Evaluation**: Assessing the performance of both unsupervised and supervised models.\n",
        "\n",
        "**Benchmark Model**\n",
        "\n",
        "For benchmarking, we will compare our unsupervised learning insights and logistic regression predictions against a simple moving average model, which is a common baseline in stock price prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBehNBQweIfF"
      },
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "<!--Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms).\n",
        "\n",
        "**Evaluation Metrics:**-->\n",
        "\n",
        "To quantify the performance of our machine learning models in predicting stock prices and categorizing stocks based on risk-return profiles, we will use the following evaluation metrics:\n",
        "\n",
        "1. **Silhouette Score**: This metric will be used to evaluate the quality of the clusters formed by our unsupervised learning algorithms. It measures how similar an object is to its own cluster compared to other clusters. The Silhouette Score ranges from -1 to 1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.\n",
        "\n",
        "   - Mathematical representation:\n",
        "     $$\n",
        "     s(i) = \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}}\n",
        "     $$\n",
        "     where $a(i)$ is the average distance from the $i$-th object to the other objects in the same cluster, and $b(i)$ is the minimum average distance from the $i$-th object to objects in a different cluster.\n",
        "\n",
        "2. **Mean Squared Error (MSE)**: For the supervised learning model that predicts stock prices, we will use MSE to measure the average of the squares of the errors between the predicted and actual prices. It is a common metric for regression models.\n",
        "\n",
        "   - Mathematical representation:\n",
        "     $$\n",
        "     \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
        "     $$\n",
        "     where $y_i$ is the actual stock price and $\\hat{y}_i$ is the predicted stock price.\n",
        "\n",
        "3. **Root Mean Squared Error (RMSE)**: RMSE is the square root of MSE and provides a measure of the average error in the same units as the stock prices. It is useful for comparing the performance of different models.\n",
        "\n",
        "   - Mathematical representation:\n",
        "     $$\n",
        "     \\text{RMSE} = \\sqrt{\\text{MSE}}\n",
        "     $$\n",
        "\n",
        "4. **Portfolio Stability**: To evaluate the effectiveness of the unsupervised learning approach in optimizing investment portfolios, we will compare the stability of portfolios constructed based on the identified stock categories with those constructed using traditional methods. Portfolio stability can be measured in terms of the variance of portfolio returns over time.\n",
        "\n",
        "   - Mathematical representation:\n",
        "     $$\n",
        "     \\text{Portfolio Stability} = \\text{Var}(R_p)\n",
        "     $$\n",
        "     where $R_p$ is the return of the portfolio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0ubsHi7eIfF"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1otjcEdeIfF"
      },
      "source": [
        "### Subsection 1: Dataset Analysis and Algorithm Selection\n",
        "\n",
        "**Reponse:** We are conducting a detailed analysis of the Apple Inc. stock price dataset. We'll explore its features, look for correlations, and identify trends that could inform our model selection. A comprehensive exploratory data analysis (EDA) will be performed to understand the characteristics and distribution of the data. Given the time-series nature of stock prices, we'll discuss why algorithms like ARIMA, or more traditional regression techniques are appropriate for predicting stock prices.\n",
        "\n",
        "### Subsection 2: Exploratora data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y8S83bMueIfF",
        "outputId": "b2dc2c13-1d89-4553-d278-8c7974856e0f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Exploratora data Analysis (EDA)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot closing stock prices\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(df.index, df['Close'])\n",
        "plt.title('Apple Inc. Stock Price')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Price')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BKgJvMVeIfF"
      },
      "source": [
        "**Response:** We made a plot that represents the prices over time (1980 to 2022)to understand the correlation between price and years for Apple Inc. using EDA. The price has consistently increased from 1980 to 2021, but the data shows a decreasing pattern between 2021 to 2022.\n",
        "\n",
        "### Subsection 3: Baseline Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ycFpKJkReIfF",
        "outputId": "75585229-da8e-4f83-8473-472bab629839"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/derricklin/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
            "  self._init_dates(dates, freq)\n",
            "/Users/derricklin/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
            "  self._init_dates(dates, freq)\n",
            "/Users/derricklin/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
            "  self._init_dates(dates, freq)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                               SARIMAX Results                                \n",
            "==============================================================================\n",
            "Dep. Variable:       Normalized_Price   No. Observations:                10468\n",
            "Model:                 ARIMA(1, 1, 1)   Log Likelihood               43451.477\n",
            "Date:                Tue, 13 May 2025   AIC                         -86896.954\n",
            "Time:                        16:54:54   BIC                         -86875.186\n",
            "Sample:                             0   HQIC                        -86889.603\n",
            "                              - 10468                                         \n",
            "Covariance Type:                  opg                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "ar.L1          0.2059      0.034      6.062      0.000       0.139       0.272\n",
            "ma.L1         -0.2649      0.034     -7.862      0.000      -0.331      -0.199\n",
            "sigma2      1.451e-05   3.79e-08    383.202      0.000    1.44e-05    1.46e-05\n",
            "===================================================================================\n",
            "Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):           1290916.09\n",
            "Prob(Q):                              0.97   Prob(JB):                         0.00\n",
            "Heteroskedasticity (H):           19754.93   Skew:                            -0.25\n",
            "Prob(H) (two-sided):                  0.00   Kurtosis:                        57.40\n",
            "===================================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
          ]
        }
      ],
      "source": [
        "# model building\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "model = ARIMA(df['Normalized_Price'], order=(1, 1, 1)) # Fit an ARIMA model; the order (p,d,q) needs to be optimized\n",
        "model_fit = model.fit()\n",
        "\n",
        "print(model_fit.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "L_fgMBjFeIfG",
        "outputId": "2fb008df-c7ac-42ef-b0a6-4370c0882c5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 0.00011421255331926562, RMSE: 0.010687027337817828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/derricklin/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
            "  return get_prediction_index(\n",
            "/Users/derricklin/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
            "  return get_prediction_index(\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model using MSE and RMSE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Make predictions\n",
        "predictions = model_fit.forecast(steps=5)  # forecast next 5\n",
        "\n",
        "# Select the actual last 5 values from the dataset for comparison\n",
        "actual = df['Normalized_Price'].iloc[-5:]\n",
        "\n",
        "mse = mean_squared_error(actual, predictions)\n",
        "rmse = sqrt(mse)\n",
        "\n",
        "print(f'MSE: {mse}, RMSE: {rmse}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En0LkB3PeIfG"
      },
      "source": [
        "**Response:**  We have established a baseline model, using a naive forecast where tomorrow's price is assumed to be today's price. We'll measure the performance of this baseline model using metrics such as MSE and RMSE. This will set the stage for comparison with more sophisticated models later on. When forecasting the next five days of stock prices using our ARIMA model, we observed the following performance metrics:\n",
        "\n",
        "Model MSE: 0.00081141255319326562\n",
        "Model RMSE: 0.01068702773817828\n",
        "\n",
        "### Subsection 4: Benchmark Model Comparsion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "o5i9n68geIfG",
        "outputId": "3e1654ad-a35c-4caf-f186-05edcbcde405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Benchmark MSE: 0.46975666970953117\n",
            "Benchmark RMSE: 0.6853879702106911\n",
            "Model MSE: 0.4698015511693662\n",
            "Model RMSE: 0.6854207110741302\n"
          ]
        }
      ],
      "source": [
        "# Benchmark model\n",
        "\n",
        "# Shift the current price to the next day for a naive forecast\n",
        "df['Naive_Forecast'] = df['Adj Close'].shift(1)\n",
        "\n",
        "# Calculate the Mean Squared Error and Root Mean Squared Error for the benchmark model\n",
        "mse_benchmark = ((df['Adj Close'] - df['Naive_Forecast']) ** 2).mean()\n",
        "rmse_benchmark = mse_benchmark ** 0.5\n",
        "\n",
        "print(f\"Benchmark MSE: {mse_benchmark}\")\n",
        "print(f\"Benchmark RMSE: {rmse_benchmark}\")\n",
        "\n",
        "df['Predicted_Price'] = df['Adj Close'].shift(-1)  # Shifting upward to create a prediction for the next day\n",
        "mse_model = ((df['Adj Close'][1:-1] - df['Predicted_Price'][1:-1]) ** 2).mean()\n",
        "rmse_model = mse_model ** 0.5\n",
        "print(f\"Model MSE: {mse_model}\")\n",
        "print(f\"Model RMSE: {rmse_model}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "93mQFEHbeIfG",
        "outputId": "6683fa34-99f2-42cd-ad41-5a4fc5c6e1d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Difference in MSE: 4.488145983505554e-05\n",
            "Difference in RMSE: 3.2740863439073564e-05\n"
          ]
        }
      ],
      "source": [
        "# Compare benchmark with our models\n",
        "print(f\"Difference in MSE: {mse_model - mse_benchmark}\")\n",
        "print(f\"Difference in RMSE: {rmse_model - rmse_benchmark}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crtvA3moeIfG"
      },
      "source": [
        "**Response:** We compared predictive models' metrics against those of a simple naive benchmark model. The benchmark model assumes that tomorrow stock price will be the same as today, provides as a baseline for assessing the effectiveness of our more complex models. These results were then compared to our naive benchmark:\n",
        "\n",
        "Benchmark MSE: 0.46975666970953117\n",
        "Benchmark RMSE: 0.6853879720616911\n",
        "\n",
        "Difference in MSE: 4.488145983505554e-05\n",
        "Difference in RMSE: 3.2740863439073564e-05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directional Accuracy: 47.06%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/gr/lxv_0bss72g0cdbpdzx5pw7m0000gn/T/ipykernel_78307/2947074714.py:5: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
            "  df['Predicted_Return'] = df['Predicted_Price'].pct_change()\n"
          ]
        }
      ],
      "source": [
        "# Calculate actual daily returns (using Adj Close for consistency)\n",
        "df['Actual_Return'] = df['Adj Close'].pct_change()\n",
        "\n",
        "# Calculate predicted daily returns (shift predictions to align with actuals)\n",
        "df['Predicted_Return'] = df['Predicted_Price'].pct_change()\n",
        "\n",
        "# Drop rows with NaN values (first row and any missing predictions)\n",
        "df_direction = df.dropna(subset=['Actual_Return', 'Predicted_Return'])\n",
        "\n",
        "# Calculate directional accuracy\n",
        "correct_direction = (\n",
        "    (df_direction['Actual_Return'] > 0) & (df_direction['Predicted_Return'] > 0)\n",
        ") | (\n",
        "    (df_direction['Actual_Return'] < 0) & (df_direction['Predicted_Return'] < 0)\n",
        ")\n",
        "\n",
        "directional_accuracy = correct_direction.sum() / len(correct_direction)\n",
        "print(f\"Directional Accuracy: {directional_accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Directional Accuracy\n",
        "Directional accuracy measures how often our model correctly predicts the direction of Apple’s stock price movement (up or down) from one day to the next. In our analysis, the model achieved a directional accuracy of 47.06%.\n",
        "\n",
        "## What Does This Mean?\n",
        "A directional accuracy of 47.06% means that the model correctly predicted whether the stock price would increase or decrease on the following day in about 47 out of every 100 trading days. In other words, the model’s predictions about the direction of price movement were correct less than half the time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Improving our Directional Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directional Accuracy: 52.77%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/gr/lxv_0bss72g0cdbpdzx5pw7m0000gn/T/ipykernel_78307/320220601.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Direction'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n"
          ]
        }
      ],
      "source": [
        "# 1. Create the target variable\n",
        "df['Direction'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
        "\n",
        "# 2. Select features you already have\n",
        "features = ['Close', 'Open', 'High', 'Low', 'Volume', 'Daily_Return', 'Overnight_Return']\n",
        "\n",
        "# 3. Drop rows with missing values in features or target\n",
        "df_model = df.dropna(subset=features + ['Direction'])\n",
        "\n",
        "# 4. Prepare X and y\n",
        "X = df_model[features]\n",
        "y = df_model['Direction']\n",
        "\n",
        "# 5. Time series train/test split (no shuffle)\n",
        "split_idx = int(len(X) * 0.8)\n",
        "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
        "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
        "\n",
        "# 6. Fit logistic regression and evaluate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "directional_accuracy = (y_pred == y_test).mean()\n",
        "print(f\"Directional Accuracy: {directional_accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# How I improved Directional Accuracy\n",
        "\n",
        "After implementing a simple logistic regression model using only features already present in our dataset, we observed a notable improvement in directional accuracy from 47.06% to 52.77%. This increase demonstrates that even basic machine learning techniques, when applied thoughtfully to relevant features, can enhance our ability to predict the direction of Apple’s stock price movements. By reframing the problem as a classification task (predicting whether the next day’s price will go up or down) and leveraging multiple features such as price, volume, and daily returns, the model was able to capture more nuanced patterns in the data. Achieving a directional accuracy above 50% suggests that the model is now performing better than random guessing, providing a modest but meaningful predictive edge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKJuFAoLeIfG"
      },
      "source": [
        "# Discussion\n",
        "\n",
        "### Interpreting the result\n",
        "\n",
        "<!--OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.-->\n",
        "\n",
        "**Main Point**:\n",
        "\n",
        "The comparison between our ARIMA model and the naive benchmark model suggests that our ARIMA model performs slightly better in predicting Apple's stock prices, as supported by its slightly lower MSE and RMSE values. However, the improvement in predictive accuracy over the simpler benchmark model is not significant, despite the ARIMA model's added complexity.\n",
        "\n",
        "\n",
        "**Secondary Points**:\n",
        "\n",
        "Model Performance: Although the ARIMA model is slightly better than the benchmark, both models shows relatively low MSE and RMSE values, which means that they reasonably capture the general trends in Apple's stock prices. This implies that while more complex models may provide additional improvement, simple approaches can yield useful predictions.\n",
        "\n",
        "Validating Model Effectiveness: Conducting comparisons against simpler models allows us to evaluate whether the increased complexity of advanced techniques, such as ARIMA, results in a significant improvement in predictive accuracy. By quantifying the differences in performance metrics between the ARIMA model and the benchmark, we understand the added value of employing advanced techniques in stock price prediction.\n",
        "\n",
        "Practical Implications: While the ARIMA model outperforms the naive benchmark, the differences in MSE and RMSE are relatively small. This suggests that investors and analysts may need to consider factors beyond predictive accuracy, such as model complexity and computational resources when selecting a suitable forecasting approach.\n",
        "\n",
        "\n",
        "### Limitations\n",
        "\n",
        "As the ARIMA prediction model relies on historical data to make predictions, it is only natural that the predictions will be based on the data that was fed to the model.\n",
        "Therefore, while it may make accurate predictions given the past data of apple stocks, it can’t be said that this model would remain accurate in the future.\n",
        "As with all prediction models, it cannot account for any sudden changes that may occur in the future.\n",
        "For example, if we had tried to use this ARIMA prediction model to predict the change in Apple’s stock prices from 2018 and onward, the model wouldn’t have been able to take into account the COVID-19 pandemic that started in 2019.\n",
        "The unexpected changes that might come in the future is unpredictable, and a main limitation that comes with predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppQG6LkVeIfG"
      },
      "source": [
        "# Ethics & Privacy\n",
        "\n",
        "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
        "\n",
        "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
        "\n",
        "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
        "\n",
        "**Ethics and Privacy:**\n",
        "\n",
        "In developing a machine learning model to predict stock prices, we are committed to upholding the highest ethical standards and ensuring the privacy and security of the data used. Our approach is guided by the following principles:\n",
        "\n",
        "- **Data Source Transparency:** We will only use publicly available financial data from reputable sources, such as stock exchanges, financial news websites, and government reports. We will clearly document the sources of our data to ensure transparency and accountability.\n",
        "\n",
        "- **Anonymity and Privacy:** While stock market data is generally anonymized and does not contain personal information, we will rigorously review the datasets to ensure that there is no indirect way to identify individuals or private entities. Any data that could potentially lead to identification will be further anonymized or excluded from our analysis.\n",
        "\n",
        "- **Informed Consent:** For any data that may involve individual contributors or proprietary information, we will ensure that informed consent has been obtained. This includes clear communication about the purpose of the data collection and the intended use of the data in our project.\n",
        "\n",
        "- **Bias and Fairness:** We recognize that financial markets can be influenced by a wide range of factors, including economic, political, and social elements. We will critically assess our model for any biases that may arise from the data or the algorithms used. Efforts will be made to ensure that our predictions do not inadvertently favor or disadvantage any particular group or individual.\n",
        "\n",
        "- **Responsible Use of Predictions:** We are aware of the potential impact that stock price predictions can have on individuals, companies, and the economy. Our project is intended for academic purposes and should not be used as financial advice. We will clearly communicate the limitations and uncertainties of our predictions to prevent misuse or overreliance on our model.\n",
        "\n",
        "- **Compliance with Regulations:** We will adhere to all relevant laws and regulations related to financial data and securities trading. This includes respecting insider trading laws and ensuring that our project does not contribute to market manipulation or other unethical practices.\n",
        "\n",
        "By adhering to these principles, we aim to conduct our project with integrity and respect for the privacy and rights of all stakeholders involved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9uyKMCheIfG"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "Comparing the RMSE and MSE values between the naive benchmark model and the ARMIA model, we can see that the ARIMA model seems to perform slightly better than the naive benchmark model in predicting the Apple stock values.\n",
        "This can be concluded by observing that the RMSE and MSE values of the ARIMA model is slightly lower than the RMSE and MSE values of the naive benchmark model.\n",
        "Considering the performance of the ARIMA model, there might be a need to explore other factors such as computing resources in comparison the amount of increased performance in a model, before determining if one model should be chosen over another.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSPLfy-MeIfG"
      },
      "source": [
        "# Footnotes\n",
        "<a name=\"lorenznote\"></a>1.[^](#simplilearn): Biswal, Avijeet (2023) *Stock Price Prediction using Machine Learning* https://www.simplilearn.com/tutorials/machine-learning-tutorial/stock-price-prediction-using-machine-learning#what_is_the_stock_market<br>\n",
        "<a name=\"admonishnote\"></a>2.[^](#projectpro): Raval, Param (2024) *Stock Price Predicition using Machine Learning with Source Code* https://www.projectpro.io/article/stock-price-prediction-using-machine-learning-project/571<br>\n",
        "<a name=\"sotanote\"></a>3.[^](#neptuneai): Li, Katherene (2023) *Predicting Stock Prices using Machine Learning*\n",
        "\n",
        "<a name=\"MEETNAGADIA\"></a>4.[^](#sdsu): Dehaven, Addison (2023) *SDSU researchers develop AI-powered model to predict stock market trends* https://www.sdstate.edu/news/2023/11/sdsu-researchers-develop-ai-powered-model-predict-stock-market-trends\n",
        "\n",
        "<a name=\"Meet Nagadia\"></a>5.[^](#Kaggle): Meet, Nagadia (2022) *Apple Stock Price from 1980-2021* https://www.kaggle.com/datasets/meetnagadia/apple-stock-price-from-19802021\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
